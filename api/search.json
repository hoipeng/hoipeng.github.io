[{"id":"291181833de5959f3812d44148347dd4","title":"Docker部署Harbor","content":"\n执行以下脚本，创建必要目录并且下载和解压harbor安装包：\n\nmkdir -p &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5\n&amp;&amp; mkdir -p &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;log \n&amp;&amp; mkdir -p &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;data \n&amp;&amp; mkdir -p &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;data&#x2F;secret \n&amp;&amp; cd &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5 \n&amp;&amp; wget https:&#x2F;&#x2F;github.com&#x2F;goharbor&#x2F;harbor&#x2F;releases&#x2F;download&#x2F;v2.5.5&#x2F;harbor-online-installer-v2.5.5.tgz\n&amp;&amp; tar -zxvf harbor-online-installer-v2.5.5.tgz\n&amp;&amp; mkdir -p &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;harbor&#x2F;common&#x2F;config\n\n\n打开/volume1/docker/harbor-2.5.5/harbor/harbor.yml文件，修改参数\n\n\n\n\n\n\n\n\n\n\n默认不存在harbor.yml文件，需要手动复制一份\ncp &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;harbor&#x2F;harbor.yml.tmpl &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;harbor&#x2F;harbor.yml\n修改内容如下：\n\n\n\n\n\n\n\n\n\n\n修改hostname，如果有域名就用域名，否则改成IP地址\n\n修改http端口\n\n修改存储数据的位置\n\n修改日志存储路径\n\n\n# Configuration file of Harbor\n\n# The IP address or hostname to access admin UI and registry service.\n# DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients.\n## 1. 修改hostname，如果有域名就用域名，否则改成IP地址\nhostname: 192.168.1.101\n\n# http related config\nhttp:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  ## 2. 选一个没有占用的端口作为http端口\n  port: 20080\n\n# https related config\n# 如果不使用https的话，注释所有https的配置\n#https:\n  # https port for harbor, default is 443\n  #port: 443\n  # The path of cert and key files for nginx\n  #certificate: &#x2F;your&#x2F;certificate&#x2F;path\n  #private_key: &#x2F;your&#x2F;private&#x2F;key&#x2F;path\n\n# # Uncomment following will enable tls communication between all harbor components\n# internal_tls:\n#   # set enabled to true means internal tls is enabled\n#   enabled: true\n#   # put your cert and key files on dir\n#   dir: &#x2F;etc&#x2F;harbor&#x2F;tls&#x2F;internal\n\n# Uncomment external_url if you want to enable external proxy\n# And when it enabled the hostname will no longer used\n# external_url: https:&#x2F;&#x2F;reg.mydomain.com:8433\n\n# The initial password of Harbor admin\n# It only works in first time to install harbor\n# Remember Change the admin password from UI after launching Harbor.\nharbor_admin_password: Harbor12345\n\n# Harbor DB configuration\ndatabase:\n  # The password for the root user of Harbor DB. Change this before any production use.\n  password: root123\n  # The maximum number of connections in the idle connection pool. If it &lt;&#x3D;0, no idle connections are retained.\n  max_idle_conns: 100\n  # The maximum number of open connections to the database. If it &lt;&#x3D; 0, then there is no limit on the number of open connections.\n  # Note: the default number of connections is 1024 for postgres of harbor.\n  max_open_conns: 900\n\n# The default data volume\n## 3. 修改存储数据的位置\ndata_volume: &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;data\n\n# Harbor Storage settings by default is using &#x2F;data dir on local filesystem\n# Uncomment storage_service setting If you want to using external storage\n# storage_service:\n#   # ca_bundle is the path to the custom root ca certificate, which will be injected into the truststore\n#   # of registry&#39;s and chart repository&#39;s containers.  This is usually needed when the user hosts a internal storage with self signed certificate.\n#   ca_bundle:\n\n#   # storage backend, default is filesystem, options include filesystem, azure, gcs, s3, swift and oss\n#   # for more info about this configuration please refer https:&#x2F;&#x2F;docs.docker.com&#x2F;registry&#x2F;configuration&#x2F;\n#   filesystem:\n#     maxthreads: 100\n#   # set disable to true when you want to disable registry redirect\n#   redirect:\n#     disabled: false\n\n# Trivy configuration\n#\n# Trivy DB contains vulnerability information from NVD, Red Hat, and many other upstream vulnerability databases.\n# It is downloaded by Trivy from the GitHub release page https:&#x2F;&#x2F;github.com&#x2F;aquasecurity&#x2F;trivy-db&#x2F;releases and cached\n# in the local file system. In addition, the database contains the update timestamp so Trivy can detect whether it\n# should download a newer version from the Internet or use the cached one. Currently, the database is updated every\n# 12 hours and published as a new release to GitHub.\ntrivy:\n  # ignoreUnfixed The flag to display only fixed vulnerabilities\n  ignore_unfixed: false\n  # skipUpdate The flag to enable or disable Trivy DB downloads from GitHub\n  #\n  # You might want to enable this flag in test or CI&#x2F;CD environments to avoid GitHub rate limiting issues.\n  # If the flag is enabled you have to download the &#96;trivy-offline.tar.gz&#96; archive manually, extract &#96;trivy.db&#96; and\n  # &#96;metadata.json&#96; files and mount them in the &#96;&#x2F;home&#x2F;scanner&#x2F;.cache&#x2F;trivy&#x2F;db&#96; path.\n  skip_update: false\n  #\n  # The offline_scan option prevents Trivy from sending API requests to identify dependencies.\n  # Scanning JAR files and pom.xml may require Internet access for better detection, but this option tries to avoid it.\n  # For example, the offline mode will not try to resolve transitive dependencies in pom.xml when the dependency doesn&#39;t\n  # exist in the local repositories. It means a number of detected vulnerabilities might be fewer in offline mode.\n  # It would work if all the dependencies are in local.\n  # This option doesn’t affect DB download. You need to specify &quot;skip-update&quot; as well as &quot;offline-scan&quot; in an air-gapped environment.\n  offline_scan: false\n  #\n  # insecure The flag to skip verifying registry certificate\n  insecure: false\n  # github_token The GitHub access token to download Trivy DB\n  #\n  # Anonymous downloads from GitHub are subject to the limit of 60 requests per hour. Normally such rate limit is enough\n  # for production operations. If, for any reason, it&#39;s not enough, you could increase the rate limit to 5000\n  # requests per hour by specifying the GitHub access token. For more details on GitHub rate limiting please consult\n  # https:&#x2F;&#x2F;developer.github.com&#x2F;v3&#x2F;#rate-limiting\n  #\n  # You can create a GitHub token by following the instructions in\n  # https:&#x2F;&#x2F;help.github.com&#x2F;en&#x2F;github&#x2F;authenticating-to-github&#x2F;creating-a-personal-access-token-for-the-command-line\n  #\n  # github_token: xxx\n\njobservice:\n  # Maximum number of job workers in job service\n  max_job_workers: 10\n\nnotification:\n  # Maximum retry count for webhook job\n  webhook_job_max_retry: 10\n\nchart:\n  # Change the value of absolute_url to enabled can enable absolute url in chart\n  absolute_url: disabled\n\n# Log configurations\nlog:\n  # options are debug, info, warning, error, fatal\n  level: info\n  # configs for logs in local storage\n  local:\n    # Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.\n    rotate_count: 50\n    # Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.\n    # If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G\n    # are all valid.\n    rotate_size: 200M\n    # The directory on your host that store log\n    ## 4. 修改日志存储路径，这个文件夹之前就创建好了\n    location: &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;log\n\n  # Uncomment following lines to enable external syslog endpoint.\n  # external_endpoint:\n  #   # protocol used to transmit log to external endpoint, options is tcp or udp\n  #   protocol: tcp\n  #   # The host of external endpoint\n  #   host: localhost\n  #   # Port of external endpoint\n  #   port: 5140\n\n#This attribute is for migrator to detect the version of the .cfg file, DO NOT MODIFY!\n_version: 2.5.0\n\n# Uncomment external_database if using external database.\n# external_database:\n#   harbor:\n#     host: harbor_db_host\n#     port: harbor_db_port\n#     db_name: harbor_db_name\n#     username: harbor_db_username\n#     password: harbor_db_password\n#     ssl_mode: disable\n#     max_idle_conns: 2\n#     max_open_conns: 0\n#   notary_signer:\n#     host: notary_signer_db_host\n#     port: notary_signer_db_port\n#     db_name: notary_signer_db_name\n#     username: notary_signer_db_username\n#     password: notary_signer_db_password\n#     ssl_mode: disable\n#   notary_server:\n#     host: notary_server_db_host\n#     port: notary_server_db_port\n#     db_name: notary_server_db_name\n#     username: notary_server_db_username\n#     password: notary_server_db_password\n#     ssl_mode: disable\n\n# Uncomment external_redis if using external Redis server\n# external_redis:\n#   # support redis, redis+sentinel\n#   # host for redis: &lt;host_redis&gt;:&lt;port_redis&gt;\n#   # host for redis+sentinel:\n#   #  &lt;host_sentinel1&gt;:&lt;port_sentinel1&gt;,&lt;host_sentinel2&gt;:&lt;port_sentinel2&gt;,&lt;host_sentinel3&gt;:&lt;port_sentinel3&gt;\n#   host: redis:6379\n#   password:\n#   # sentinel_master_set must be set to support redis+sentinel\n#   #sentinel_master_set:\n#   # db_index 0 is for core, it&#39;s unchangeable\n#   registry_db_index: 1\n#   jobservice_db_index: 2\n#   chartmuseum_db_index: 3\n#   trivy_db_index: 5\n#   idle_timeout_seconds: 30\n\n# Uncomment uaa for trusting the certificate of uaa instance that is hosted via self-signed cert.\n# uaa:\n#   ca_file: &#x2F;path&#x2F;to&#x2F;ca\n\n# Global proxy\n# Config http proxy for components, e.g. http:&#x2F;&#x2F;my.proxy.com:3128\n# Components doesn&#39;t need to connect to each others via http proxy.\n# Remove component from &#96;components&#96; array if want disable proxy\n# for it. If you want use proxy for replication, MUST enable proxy\n# for core and jobservice, and set &#96;http_proxy&#96; and &#96;https_proxy&#96;.\n# Add domain to the &#96;no_proxy&#96; field, when you want disable proxy\n# for some special registry.\nproxy:\n  http_proxy:\n  https_proxy:\n  no_proxy:\n  components:\n    - core\n    - jobservice\n    - trivy\n\n# metric:\n#   enabled: false\n#   port: 9090\n#   path: &#x2F;metrics\n\n# Trace related config\n# only can enable one trace provider(jaeger or otel) at the same time,\n# and when using jaeger as provider, can only enable it with agent mode or collector mode.\n# if using jaeger collector mode, uncomment endpoint and uncomment username, password if needed\n# if using jaeger agetn mode uncomment agent_host and agent_port\n# trace:\n#   enabled: true\n#   # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth\n#   sample_rate: 1\n#   # # namespace used to differenciate different harbor services\n#   # namespace:\n#   # # attributes is a key value dict contains user defined attributes used to initialize trace provider\n#   # attributes:\n#   #   application: harbor\n#   # # jaeger should be 1.26 or newer.\n#   # jaeger:\n#   #   endpoint: http:&#x2F;&#x2F;hostname:14268&#x2F;api&#x2F;traces\n#   #   username:\n#   #   password:\n#   #   agent_host: hostname\n#   #   # export trace data by jaeger.thrift in compact mode\n#   #   agent_port: 6831\n#   # otel:\n#   #   endpoint: hostname:4318\n#   #   url_path: &#x2F;v1&#x2F;traces\n#   #   compression: false\n#   #   insecure: true\n#   #   timeout: 10s\n\n# enable purge _upload directories\nupload_purging:\n  enabled: true\n  # remove files in _upload directories which exist for a period of time, default is one week.\n  age: 168h\n  # the interval of the purge operations\n  interval: 24h\n  dryrun: false\n \n\n\n\n\n修改完成后，执行准备命令\n\ncd &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;harbor \n&amp;&amp; sudo .&#x2F;prepare\n\n\n开始安装\n\ncd &#x2F;volume1&#x2F;docker&#x2F;harbor-2.5.5&#x2F;harbor \n&amp;&amp; sudo .&#x2F;install.sh\n\n\n安装完成\n\n\n浏览器登录harbor，\n\n\n\n\n\n\n\n\n\n地址：http://192.168.1.101:20080\n账号&#x2F;密码：admin&#x2F;Harbor12345\n\n\n\n","slug":"Docker部署Harbor","date":"2023-01-30T01:13:40.000Z","categories_index":"程序猿🐒","tags_index":"","author_index":"慎独丶九思"},{"id":"2ca528413d98d2a6052186d4e6e5f17c","title":"Debian安装podman","content":"安装Podman\nPodman 软件包包含在 Debian 11 默认存储库中，只需运行以下命令即可安装它:\n\napt-get install podman -y\n\n\n\n安装完成后查看版本号\n\npodman --version\n\n\n\n查看podman更多信息\n\nroot@debian-gnu-linux-11:~# podman info\nhost:\n  arch: arm64\n  buildahVersion: 1.19.6\n  cgroupManager: systemd\n  cgroupVersion: v2\n  conmon:\n    package: &#39;conmon: &#x2F;usr&#x2F;bin&#x2F;conmon&#39;\n    path: &#x2F;usr&#x2F;bin&#x2F;conmon\n    version: &#39;conmon version 2.0.25, commit: unknown&#39;\n  cpus: 2\n  distribution:\n    distribution: debian\n    version: &quot;11&quot;\n  eventLogger: journald\n  hostname: debian-gnu-linux-11\n  idMappings:\n    gidmap: null\n    uidmap: null\n  kernel: 5.10.0-15-arm64\n  linkmode: dynamic\n  memFree: 902115328\n  memTotal: 2078269440\n  ociRuntime:\n    name: crun\n    package: &#39;crun: &#x2F;usr&#x2F;bin&#x2F;crun&#39;\n    path: &#x2F;usr&#x2F;bin&#x2F;crun\n    version: |-\n      crun version 0.17\n      commit: 0e9229ae34caaebcb86f1fde18de3acaf18c6d9a\n      spec: 1.0.0\n      +SYSTEMD +SELINUX +APPARMOR +CAP +SECCOMP +EBPF +YAJL\n  os: linux\n  remoteSocket:\n    exists: true\n    path: &#x2F;run&#x2F;podman&#x2F;podman.sock\n  security:\n    apparmorEnabled: true\n    capabilities: CAP_CHOWN,CAP_DAC_OVERRIDE,CAP_FOWNER,CAP_FSETID,CAP_KILL,CAP_NET_BIND_SERVICE,CAP_SETFCAP,CAP_SETGID,CAP_SETPCAP,CAP_SETUID,CAP_SYS_CHROOT\n    rootless: false\n    seccompEnabled: true\n    selinuxEnabled: false\n  slirp4netns:\n    executable: &quot;&quot;\n    package: &quot;&quot;\n    version: &quot;&quot;\n  swapFree: 1023406080\n  swapTotal: 1023406080\n  uptime: 46m 8.14s\nregistries: &#123;&#125;\nstore:\n  configFile: &#x2F;etc&#x2F;containers&#x2F;storage.conf\n  containerStore:\n    number: 0\n    paused: 0\n    running: 0\n    stopped: 0\n  graphDriverName: overlay\n  graphOptions: &#123;&#125;\n  graphRoot: &#x2F;var&#x2F;lib&#x2F;containers&#x2F;storage\n  graphStatus:\n    Backing Filesystem: extfs\n    Native Overlay Diff: &quot;true&quot;\n    Supports d_type: &quot;true&quot;\n    Using metacopy: &quot;false&quot;\n  imageStore:\n    number: 0\n  runRoot: &#x2F;run&#x2F;containers&#x2F;storage\n  volumePath: &#x2F;var&#x2F;lib&#x2F;containers&#x2F;storage&#x2F;volumes\nversion:\n  APIVersion: 3.0.0\n  Built: 0\n  BuiltTime: Thu Jan  1 08:00:00 1970\n  GitCommit: &quot;&quot;\n  GoVersion: go1.15.15\n  OsArch: linux&#x2F;arm64\n  Version: 3.0.1\n\nroot@debian-gnu-linux-11:~# \n\n配置国内镜像源vim &#x2F;etc&#x2F;containers&#x2F;registries.conf\n# 在文本末尾增加以下几行\nunqualified-search-registries &#x3D; [&quot;docker.io&quot;]\n \n[[registry]]\nprefix &#x3D; &quot;docker.io&quot;\nlocation &#x3D; &quot;xxxxxxx.mirror.aliyuncs.com&quot;\n\n","slug":"Debian安装podman","date":"2022-12-27T05:27:05.000Z","categories_index":"程序猿🐒","tags_index":"","author_index":"慎独丶九思"},{"id":"970f7f1adf4d90e614a9db3caafa2ba6","title":"Feign报错","content":"Feign报错feign.RetryableException: too many bytes written executing_乔一I的博客-CSDN博客_too many bytes written executingCreated: December 23, 2022 11:04 AMURL: https://blog.csdn.net/qq_39986681/article/details/107138740?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107138740-blog-106431593.pc_relevant_vip_default&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107138740-blog-106431593.pc_relevant_vip_default&amp;utm_relevant_index=1\n版本:\n\n\n\n\n\n\n\n\n\nSpringCloud : 2021.0.4\nSpringBoot : 2.7.3\nSpringCloudAlibaba : 2021.0.4.0\n百度到body是跟Content-Length 有关系的… 附上博主链接 https://my.oschina.net/u/4410077/blog/3323588 因为服务之间调用需要携带一些用户信息之类的 所以实现了Feign的RequestInterceptor拦截器复制请求头，复制的时候是所有头都复制的,可能导致Content-length长度跟body不一致. 所以只需要判断如果是Content-length就跳过\n原配置 :\n&#x2F;**\n * @author Joe\n * createTime 2020&#x2F;06&#x2F;10 18:13\n *&#x2F;\n@Log4j2\n@Configuration\npublic class FeignConfiguration implements RequestInterceptor &#123;\n\n    @Override\n    public void apply(RequestTemplate template) &#123;\n        ServletRequestAttributes attributes &#x3D; (ServletRequestAttributes) RequestContextHolder\n                .getRequestAttributes();\n        HttpServletRequest request &#x3D; attributes.getRequest();\n        Enumeration&lt;String&gt; headerNames &#x3D; request.getHeaderNames();\n        if (headerNames !&#x3D; null) &#123;\n            while (headerNames.hasMoreElements()) &#123;\n                String name &#x3D; headerNames.nextElement();\n                String values &#x3D; request.getHeader(name);\n                template.header(name, values);\n            &#125;\n        &#125; else &#123;\n            log.info(&quot;feign interceptor error header:&#123;&#125;&quot;, template);\n        &#125;\n    &#125;\n&#125;\n\n\n修改之后:\n&#x2F;**\n * @author Joe\n * createTime 2020&#x2F;06&#x2F;10 18:13\n *&#x2F;\n@Log4j2\n@Configuration\npublic class FeignConfiguration implements RequestInterceptor &#123;\n\n    @Override\n    public void apply(RequestTemplate template) &#123;\n        ServletRequestAttributes attributes &#x3D; (ServletRequestAttributes) RequestContextHolder\n                .getRequestAttributes();\n        HttpServletRequest request &#x3D; attributes.getRequest();\n        Enumeration&lt;String&gt; headerNames &#x3D; request.getHeaderNames();\n        if (headerNames !&#x3D; null) &#123;\n            while (headerNames.hasMoreElements()) &#123;\n                String name &#x3D; headerNames.nextElement();\n                String values &#x3D; request.getHeader(name);\n                &#x2F;&#x2F; 跳过 content-length\n                if (name.equals(&quot;content-length&quot;))&#123;\n                    continue;\n                &#125;\n                template.header(name, values);\n            &#125;\n        &#125; else &#123;\n            log.info(&quot;feign interceptor error header:&#123;&#125;&quot;, template);\n        &#125;\n    &#125;\n&#125;\n\n\ncontent-length详解参考文章 ：https://juejin.im/post/5d772cb4e51d453b5f1a0502\n","slug":"Feign报错","date":"2022-12-23T03:08:58.000Z","categories_index":"程序猿🐒","tags_index":"Feign,Spring Cloud","author_index":"慎独丶九思"},{"id":"35f9da2ff904b5c3201ae1ff19769ee3","title":"MySQL创建定时器","content":"1. 介绍\n\n\n\n\n\n\n\n\n在开发过程中经常会遇到这样一个问题：每天或者每月必须定时去执行一条sql语句或更新或删除或执行特定的sql语句。\n注意: mysql定时器是从mysql5.1开始的，如果你的mysql版本低于5.1，那就不能使用mysql定时器\n2. 开启定时器\n\n\n\n\n\n\n\n\nMySQL定时器默认为关闭状态\n2.1 查询定时器是否开启\n\n\n\n\n\n\n\n\nOFF 关闭 , ON开启\nshow VARIABLES like &#39;event_scheduler&#39;;\n\n\n2.2 开启MySQL定时器SET GLOBAL event_scheduler &#x3D; 1;\n\n\n\n\n\n\n\n\n\n\n注意：如果MySQL服务器重启这个还是会关闭的\n永久解决办法:\n\n\n\n\n\n\n\n\n\n修改my.ini文件，打开并在[mysqld]标记下方添加一句event_scheduler = ON即可。\n[mysqld]\nevent_scheduler &#x3D; ON\n3. 使用sql语句创建定时器常用的语法关键字:NOT PRESERVE 任务完成后清除定时器, (默认)PRESERVE 任务完成后不清除定时器EVERY 周期执行STARTS ENDS 在某个时间段执行AT 某个时间点执行ENDS 结束定时器时间INTERVAL 间隔(时间)\n常用的单位关键字:HOUR : 小时SECOND 秒MINUTE : 分钟DAY : 天MONTH: 月\n定时器语法结构:\ndrop event if exists TEST_EVENT; -- 定时任务如果存在先删除\ncreate event TEST_EVENT -- TEST_EVENT定时任务的名称\n\t\ton schedule every 1 hour -- 每1小时执行一次\n    do call TEST_PROCEDURE(); -- 调用存储过程（存储过程名字）\n\n","slug":"MySQL创建定时器","date":"2022-12-07T12:00:00.000Z","categories_index":"程序猿🐒,数据库,MySQL","tags_index":"MySQL,数据库","author_index":"慎独丶九思"},{"id":"ae72657417f8c8230eee1e7101a8f14b","title":"Docker版Gitlab的安装与汉化","content":"一、gitlab安装1.1 镜像查询# 查询gitlab有哪些镜像\n docker search gitlab\n\n1.2 镜像拉取（重点）镜像的拉取会直接影响到后面我们汉化，所以镜像的选择尤为重要。\n可以看到主要有两个镜像，比较方便我们利用的，第一个是官方社区版的镜像，第四个是其他大神爱好者汉化社区版的镜像。后续两种镜像我都会进行介绍。\n1.2.1 官方社区版官方社区版是纯英语的，可以原汁原味地体验gitlab。而且镜像更新非常积极，新加的功能都能够体验到。\n如果使用以下命令拉取，得到的就会是最新版的gitlab。    \ndocker pull gitlab&#x2F;gitlab-ce\n\n但是最新版有个弊端就gitlab的中文比一定能马上匹配。如果想知道现在汉化匹配到什么版本了，可以查看gitlab中文社区。\nhttps://gitlab.com/xhang/gitlab/\n下面都是基于12.3.5版本。\ndocker pull gitlab&#x2F;gitlab-ce:12.3.5-ce.0\n\n1.2.2 已汉化社区版如果不想自己汉化的话，可以选择第四个是汉化社区版的镜像。\n但是这个镜像目前已经快2年没有更新维护了，gitlab版本也是上一个版本11.1。\n1.3 镜像安装镜像拉取下来后，使用docker images查看自己拉取的镜像，然后使用docker run启动gitlab容器，建议启动命令写成一个bash，防止忘记自己启动时的参数配置。\n#!&#x2F;bin&#x2F;bash\nIMAGE_NAME&#x3D;&#39;gitlab&#x2F;gitlab-ce&#39;\nCONTAINER_NAME&#x3D;&#39;gitlab-ce-zh&#39;\nCONTAINER_ID&#x3D;&#96;docker run \n                -d \n                -p 30000:80 \n                -p 37443:443 \n                -p 37022:22 \n                --restart always \n                -v &#x2F;volume1&#x2F;docker&#x2F;gitlab&#x2F;config:&#x2F;etc&#x2F;gitlab \n                -v &#x2F;volume1&#x2F;docker&#x2F;gitlab&#x2F;logs:&#x2F;var&#x2F;log&#x2F;gitlab \n                -v &#x2F;volume1&#x2F;docker&#x2F;gitlab&#x2F;data:&#x2F;var&#x2F;opt&#x2F;gitlab \n                --name $&#123;CONTAINER_NAME&#125; \n                $&#123;IMAGE_NAME&#125;&#96;\n            \n# -d：后台运行    \n# -p：将容器内部端口向外映射\n# --name：命名容器名称    \n# -v：将容器内数据文件夹或者日志、配置等文件夹挂载到宿主机指定目录    \n# 以上参数的具体用法，建议读者可以自己动手对比添加和不添加的区别，加深学习印象\n\n命令运行结束后，会出现容器ID，可以通过docker ps查看容器是否成功启动。然后访问gitlab的地址，如果能打开gitlab主页说明已经成功运行。如果使用的是中文社区版的，打开之后就是中文的了。\n\n二、gitlab配置2.1 访问url配置url的配置在&#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb里面，基本上gitlab的所有配置都可以在gitlab.rb这个文件里面完成配置。\n# url配置样例\nexternal_url &#x3D; &#39;http:&#x2F;&#x2F;127.0.0.1:80&#x2F;gitlab&#39;\n\n2.2 管理员配置首次登录还需要配置管理员密码，管理员账号为root，密码在首次登录的页面上设置。\n三、汉化如果直接使用汉化的docker镜像就不用进行这一步了。\n3.1 获取汉化包访问https://gitlab.com/xhang/gitlab/，根据自己的gitlab获取相应版本的汉化包。也可以使用大stable版本。比如12.3.5可以使用gitlab-12-3-stable-zh\n可以通过命令获取\n首先查看gitlab的版本cat &#x2F;opt&#x2F;gitlab&#x2F;embedded&#x2F;service&#x2F;gitlab-rails&#x2F;VERSION\n# 使用wget获取具体的版本\nwget https:&#x2F;&#x2F;gitlab.com&#x2F;xhang&#x2F;gitlab&#x2F;-&#x2F;archive&#x2F;v12.3.5-zh&#x2F;gitlab-v12.3.5-zh.tar.gz\n# 或者用git获取大版本\ngit clone -b gitlab-12-3-stable-zh https:&#x2F;&#x2F;gitlab.com&#x2F;xhang&#x2F;gitlab&#x2F;\n\n也可以直接下载\n3.2 汉化# 把汉化包复制到容器&#x2F;opt&#x2F;gitlab&#x2F;embedded&#x2F;service目录下    \ndocker cp [汉化包名称] [容器ID]:&#x2F;opt&#x2F;gitlab&#x2F;embedded&#x2F;service\n\n# 进去容器里面继续操作    \ndocker exec -it [容器ID] bash    \ncd &#x2F;opt&#x2F;gitlab&#x2F;embedded&#x2F;service\n\n# 把汉化包里面的所有文件复制到gitlab-rails里面    \ncp -rf [汉化包名称]&#x2F;* gitlab-rails\n    \n# 如果出现下面两条语句是正常的    \ncp: cannot overwrite non-directory &#39;gitlab-rails&#x2F;log&#39; with directory &#39;gitlab-v12.3.5-zh&#x2F;log&#39;\ncp: cannot overwrite non-directory &#39;gitlab-rails&#x2F;tmp&#39; with directory &#39;gitlab-v12.3.5-zh&#x2F;tmp&#39;\n\n# 重新加载和启动gitlab    \ngitlab-ctl reconfigure     \ngitlab-ctl restart\n\n再次访问主页，已经汉化了。\n可以使用docker commit命令把已经汉化的版本保存成镜像，方便下次迁移使用。    \ndocker commit -a &quot;[作者]&quot; [容器ID] [新的镜像名]:[tag]","slug":"Docker版Gitlab的安装与汉化","date":"2022-12-05T07:37:28.000Z","categories_index":"程序猿🐒,Docker","tags_index":"Docker","author_index":"慎独丶九思"},{"id":"7be2343f42652ac906502eeb9c266f8f","title":"Docker开放2375端口","content":"docker.service 文件内容在不同 docker 版本中不一样\n第一种编辑docker文件\nvim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service\n\n在 ExecStart 行最后面加入红框中的内容\n-H tcp:&#x2F;&#x2F;0.0.0.0:2375\n\n\n重新加载配置文件\nsystemctl daemon-reload &#x2F;&#x2F; 1，加载docker守护线程\nsystemctl restart docker &#x2F;&#x2F; 2，重启docker\n\n第二种（docker 1.13.1 版本）编辑docker文件\nvim &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service\n\n在 ExecStart 行最后面加入红框中的内容\n-H tcp:&#x2F;&#x2F;0.0.0.0:2375 -H unix:&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock \n\n\n重新加载配置文件\nsystemctl daemon-reload &#x2F;&#x2F; 1，加载docker守护线程\nsystemctl restart docker &#x2F;&#x2F; 2，重启docker","slug":"Docker开放2375端口","date":"2022-12-05T07:24:10.000Z","categories_index":"程序猿🐒,Docker","tags_index":"Docker","author_index":"慎独丶九思"},{"id":"141d320c20cacf53e8188cbc9f427f71","title":"Docker安装nacos","content":"Docker安装nacos一、下载镜像docker  pull nacos&#x2F;nacos-server\n\n\n\n二、初始化Nacos数据库&#x2F;*\n * Copyright 1999-2018 Alibaba Group Holding Ltd.\n *\n * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *&#x2F;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; config_info   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;config_info&#96; (\n  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,\n  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,\n  &#96;group_id&#96; varchar(255) DEFAULT NULL,\n  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,\n  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n  &#96;src_user&#96; text COMMENT &#39;source user&#39;,\n  &#96;src_ip&#96; varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,\n  &#96;app_name&#96; varchar(128) DEFAULT NULL,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,\n  &#96;c_desc&#96; varchar(256) DEFAULT NULL,\n  &#96;c_use&#96; varchar(64) DEFAULT NULL,\n  &#96;effect&#96; varchar(64) DEFAULT NULL,\n  &#96;type&#96; varchar(64) DEFAULT NULL,\n  &#96;c_schema&#96; text,\n  &#96;encrypted_data_key&#96; text NOT NULL COMMENT &#39;秘钥&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_configinfo_datagrouptenant&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info&#39;;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; config_info_aggr   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;config_info_aggr&#96; (\n  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,\n  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,\n  &#96;group_id&#96; varchar(255) NOT NULL COMMENT &#39;group_id&#39;,\n  &#96;datum_id&#96; varchar(255) NOT NULL COMMENT &#39;datum_id&#39;,\n  &#96;content&#96; longtext NOT NULL COMMENT &#39;内容&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL COMMENT &#39;修改时间&#39;,\n  &#96;app_name&#96; varchar(128) DEFAULT NULL,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_configinfoaggr_datagrouptenantdatum&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;,&#96;datum_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;增加租户字段&#39;;\n\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; config_info_beta   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;config_info_beta&#96; (\n  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,\n  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,\n  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,\n  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,\n  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,\n  &#96;beta_ips&#96; varchar(1024) DEFAULT NULL COMMENT &#39;betaIps&#39;,\n  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n  &#96;src_user&#96; text COMMENT &#39;source user&#39;,\n  &#96;src_ip&#96; varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,\n  &#96;encrypted_data_key&#96; text NOT NULL COMMENT &#39;秘钥&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_configinfobeta_datagrouptenant&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info_beta&#39;;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; config_info_tag   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;config_info_tag&#96; (\n  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,\n  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,\n  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,\n  &#96;tag_id&#96; varchar(128) NOT NULL COMMENT &#39;tag_id&#39;,\n  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,\n  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,\n  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n  &#96;src_user&#96; text COMMENT &#39;source user&#39;,\n  &#96;src_ip&#96; varchar(50) DEFAULT NULL COMMENT &#39;source ip&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_configinfotag_datagrouptenanttag&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;,&#96;tag_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info_tag&#39;;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; config_tags_relation   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;config_tags_relation&#96; (\n  &#96;id&#96; bigint(20) NOT NULL COMMENT &#39;id&#39;,\n  &#96;tag_name&#96; varchar(128) NOT NULL COMMENT &#39;tag_name&#39;,\n  &#96;tag_type&#96; varchar(64) DEFAULT NULL COMMENT &#39;tag_type&#39;,\n  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,\n  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,\n  &#96;nid&#96; bigint(20) NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (&#96;nid&#96;),\n  UNIQUE KEY &#96;uk_configtagrelation_configidtag&#96; (&#96;id&#96;,&#96;tag_name&#96;,&#96;tag_type&#96;),\n  KEY &#96;idx_tenant_id&#96; (&#96;tenant_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_tag_relation&#39;;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; group_capacity   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;group_capacity&#96; (\n  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,\n  &#96;group_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Group ID，空字符表示整个集群&#39;,\n  &#96;quota&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,\n  &#96;usage&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,\n  &#96;max_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,\n  &#96;max_aggr_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数，，0表示使用默认值&#39;,\n  &#96;max_aggr_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,\n  &#96;max_history_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_group_id&#96; (&#96;group_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;集群、各Group容量信息表&#39;;\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; his_config_info   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;his_config_info&#96; (\n  &#96;id&#96; bigint(64) unsigned NOT NULL,\n  &#96;nid&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n  &#96;data_id&#96; varchar(255) NOT NULL,\n  &#96;group_id&#96; varchar(128) NOT NULL,\n  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,\n  &#96;content&#96; longtext NOT NULL,\n  &#96;md5&#96; varchar(32) DEFAULT NULL,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  &#96;src_user&#96; text,\n  &#96;src_ip&#96; varchar(50) DEFAULT NULL,\n  &#96;op_type&#96; char(10) DEFAULT NULL,\n  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,\n  &#96;encrypted_data_key&#96; text NOT NULL COMMENT &#39;秘钥&#39;,\n  PRIMARY KEY (&#96;nid&#96;),\n  KEY &#96;idx_gmt_create&#96; (&#96;gmt_create&#96;),\n  KEY &#96;idx_gmt_modified&#96; (&#96;gmt_modified&#96;),\n  KEY &#96;idx_did&#96; (&#96;data_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;多租户改造&#39;;\n\n\n&#x2F;******************************************&#x2F;\n&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;\n&#x2F;*   表名称 &#x3D; tenant_capacity   *&#x2F;\n&#x2F;******************************************&#x2F;\nCREATE TABLE &#96;tenant_capacity&#96; (\n  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,\n  &#96;tenant_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Tenant ID&#39;,\n  &#96;quota&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,\n  &#96;usage&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,\n  &#96;max_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,\n  &#96;max_aggr_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数&#39;,\n  &#96;max_aggr_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,\n  &#96;max_history_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,\n  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_tenant_id&#96; (&#96;tenant_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;租户容量信息表&#39;;\n\n\nCREATE TABLE &#96;tenant_info&#96; (\n  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,\n  &#96;kp&#96; varchar(128) NOT NULL COMMENT &#39;kp&#39;,\n  &#96;tenant_id&#96; varchar(128) default &#39;&#39; COMMENT &#39;tenant_id&#39;,\n  &#96;tenant_name&#96; varchar(128) default &#39;&#39; COMMENT &#39;tenant_name&#39;,\n  &#96;tenant_desc&#96; varchar(256) DEFAULT NULL COMMENT &#39;tenant_desc&#39;,\n  &#96;create_source&#96; varchar(32) DEFAULT NULL COMMENT &#39;create_source&#39;,\n  &#96;gmt_create&#96; bigint(20) NOT NULL COMMENT &#39;创建时间&#39;,\n  &#96;gmt_modified&#96; bigint(20) NOT NULL COMMENT &#39;修改时间&#39;,\n  PRIMARY KEY (&#96;id&#96;),\n  UNIQUE KEY &#96;uk_tenant_info_kptenantid&#96; (&#96;kp&#96;,&#96;tenant_id&#96;),\n  KEY &#96;idx_tenant_id&#96; (&#96;tenant_id&#96;)\n) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;tenant_info&#39;;\n\nCREATE TABLE &#96;users&#96; (\n\t&#96;username&#96; varchar(50) NOT NULL PRIMARY KEY,\n\t&#96;password&#96; varchar(500) NOT NULL,\n\t&#96;enabled&#96; boolean NOT NULL\n);\n\nCREATE TABLE &#96;roles&#96; (\n\t&#96;username&#96; varchar(50) NOT NULL,\n\t&#96;role&#96; varchar(50) NOT NULL,\n\tUNIQUE INDEX &#96;idx_user_role&#96; (&#96;username&#96; ASC, &#96;role&#96; ASC) USING BTREE\n);\n\nCREATE TABLE &#96;permissions&#96; (\n    &#96;role&#96; varchar(50) NOT NULL,\n    &#96;resource&#96; varchar(255) NOT NULL,\n    &#96;action&#96; varchar(8) NOT NULL,\n    UNIQUE INDEX &#96;uk_role_permission&#96; (&#96;role&#96;,&#96;resource&#96;,&#96;action&#96;) USING BTREE\n);\n\nINSERT INTO users (username, password, enabled) VALUES (&#39;nacos&#39;, &#39;$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu&#39;, TRUE);\n\nINSERT INTO roles (username, role) VALUES (&#39;nacos&#39;, &#39;ROLE_ADMIN&#39;);\n\n\n\n\n三、启动Nacos#解释版 复制下面的版本注意\\后面不能有空格\ndocker run -d \\\n-e MODE&#x3D;standalone \\ # 使用单机模式\n-e SPRING_DATASOURCE_PLATFORM&#x3D;mysql \\ # 数据库类型\n-e MYSQL_SERVICE_HOST&#x3D;localhost \\ # 数据库地址\n-e MYSQL_SERVICE_USER&#x3D;root \\ # 数据库账号\n-e MYSQL_SERVICE_PASSWORD&#x3D;pyongsen \\ # 数据库密码\n-e MYSQL_SERVICE_DB_NAME&#x3D;nacos_config \\ # 数据库名称\n-e JVM_XMS&#x3D;256m \\\n-e JVM_XMX&#x3D;256m \\\n-e JVM_XMN&#x3D;256m \\\n-p 8848:8848 \\ #端口映射\n-v &#x2F;lbs&#x2F;nacos&#x2F;logs:&#x2F;nacos&#x2F;logs \\ #挂载\n--name nacos \\ #容器名 \n--restart&#x3D;always \\ # 自动启动\nnacos&#x2F;nacos-server:latest #镜像名:版本（是最新的版本直接镜像名即可）\n\ndocker run -d \\\n-e MODE&#x3D;standalone \\\n-e SPRING_DATASOURCE_PLATFORM&#x3D;mysql \\\n-e MYSQL_SERVICE_HOST&#x3D;114.132.237.53 \\\n-e MYSQL_SERVICE_USER&#x3D;root \\\n-e MYSQL_SERVICE_PASSWORD&#x3D;pyongsen \\\n-e MYSQL_SERVICE_DB_NAME&#x3D;nacos_config \\\n-e JVM_XMS&#x3D;256m \\\n-e JVM_XMX&#x3D;256m \\\n-e JVM_XMN&#x3D;256m \\\n-p 8848:8848 \\\n -v &#x2F;lbs&#x2F;nacos&#x2F;logs:&#x2F;nacos&#x2F;logs \\\n--name nacos \\\n--restart&#x3D;always \\\nnacos&#x2F;nacos-server:latest\n\n\n\n四、访问Nacos如果是本地就用本地，是服务器就将localhost替换成服务器地址http://127.0.0.1:8848/nacos\n五、坑点\nNacos-client客户端从1.0升级到2.x版本后，新增gRPC的通信方式，新增了两个端口。这两个端口在nacos原先的端口上（8848），进行一定偏移量自动生成。\n\n\n\n端口\n与主端口的偏移量\n描述\n\n\n\n9848\n1000\n客户端gRPC请求服务端端口，用于客户端向服务端发起连接和请求\n\n\n9849\n1001\n服务端gRPC请求服务端端口，用于服务间同步等\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n防火墙需要开放8848、9848、9849端口\n如果使用docker部署，需要将9848、9849端口映射出来\n如果主端口更改，相应的gRPC通信端口也要按照偏移量进行更改。例如：主端口改为18848，则对应的g RPC端口应为19848、19849，转发端口时同理。\n\n","slug":"Docker安装nacos","date":"2022-12-02T08:40:39.000Z","categories_index":"程序猿🐒,Docker","tags_index":"Docker,Nacos","author_index":"慎独丶九思"},{"id":"7d7b34d825d74f6d0b144da0dc166733","title":"Kettle 处理MQTT数据并存储至数据库","content":"Kettle 处理MQTT数据并存储至数据库1、新建【转换】test2.ktr\n2、选择【MQTT consumer】组件\n3、右键点击【编辑步骤】\n4、配置MQTT消费者连接信息\n\n\n\n\n\n\n\n\n\n\n新建message处理转换（test1.ktr）\n填写MQTT连接地址\n输入客户端ID（自己定义不重复的clientId即可）\n填写需要监听的Topics\n设置服务质量\n\n5、设置获取消息的节点\n6、处理MQTT数据\n\n\n\n\n\n\n\n\n后续操作都是在第4步时&#x3D;&#x3D;新建message处理转换&#x3D;&#x3D;中进行。\n6.1、标准JSON格式数据如果MQTT的数据为标准JSON格式的数据，可以参考该流程进行处理。\n\n1）、设置JSON数据源\n\n\n\n\n\n\n\n\n\n\n勾选&#x3D;&#x3D;源定义在一个字段里☑️&#x3D;&#x3D;\n在&#x3D;&#x3D;从字段获取源&#x3D;&#x3D;中设置需要处理的字段\n\n2）、配置需要处理的字段\n\n\n\n\n\n\n\n\n\n\n名称：下一节点获取数据的字段名\n路径：需要处理数据的JSONPath路径。JSONPath简单入门\n\n3）、保存至数据库\n6.2、文本格式数据\n\n\n\n\n\n\n\n\n\n\n获取MQTT消息的节点\n按照指定分隔符处理文本\n输出日志信息\n写入数据库\n\n1）、&#x3D;&#x3D;拆分字段&#x3D;&#x3D;组件配置\n\n\n\n\n\n\n\n\n\n\n新的字段：需要拆分的字段按照分隔符分割后，按照顺序依次赋予的变量名称。可以不与文本拆分后的数组长度一致。例如：\n需要拆分的文本：test1;test2;test3;test4;test5\n拆分后新的字段：\n​\tms&#x3D;test1\n​\tms2&#x3D;test2\n​\tms3&#x3D;test3\n​\tms4&#x3D;new4\n​\tms5&#x3D;new5\n\n&#x3D;&#x3D;新的字段的数据类型必须设置&#x3D;&#x3D;\n\n\n2）、保存至数据库中\n","slug":"Kettle","date":"2022-12-02T08:37:31.000Z","categories_index":"程序猿🐒,Kettle","tags_index":"Kettle","author_index":"慎独丶九思"},{"id":"f9b8ef2e4745193c377955a886691ae2","title":"conda常用命令","content":"conda常用命令conda --version #查看conda版本，验证是否安装\nconda update conda #更新至最新版本，也会更新其它相关包\nconda update --all #更新所有包\nconda update package_name #更新指定的包\nconda create -n env_name package_name #创建名为env_name的新环境，并在该环境下安装名为package_name 的包，可以指定新环境的版本号，例如：conda create -n python2 python&#x3D;python2.7 numpy pandas，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包\nsource activate env_name #切换至env_name环境\nsource deactivate #退出环境\nconda info -e #显示所有已经创建的环境\nconda create --name new_env_name --clone old_env_name #复制old_env_name为new_env_name\nconda remove --name env_name –all #删除环境\nconda list #查看所有已经安装的包\nconda install package_name #在当前环境中安装包\nconda install --name env_name package_name #在指定环境中安装包\nconda remove -- name env_name package #删除指定环境中的包\nconda remove package #删除当前环境中的包\nconda create -n tensorflow_env tensorflow\nconda activate tensorflow_env #conda 安装tensorflow的CPU版本\nconda create -n tensorflow_gpuenv tensorflow-gpu\nconda activate tensorflow_gpuenv #conda安装tensorflow的GPU版本\nconda env remove -n env_name #采用第10条的方法删除环境失败时，可采用这种方法\n\n","slug":"conda常用命令","date":"2022-12-02T08:34:42.000Z","categories_index":"程序猿🐒","tags_index":"conda","author_index":"慎独丶九思"},{"id":"870dd8811e397400df0eea1fed2238dc","title":"IDEA安装插件Git","content":"\ntype：用于说明commit的类别，常用的标识如下：\n\nfeat ：新功能（feature）\n\nfix ：修补BUG\n\ndocs ：文档（documentation）\n\nstyle ：格式（不影响代码运行的变动,空格,格式化,等等）\n\nrefactor ：重构（即不是新增功能，也不是修改bug的代码变动\n\nperf ：性能 (提高代码性能的改变)\n\ntest ：增加测试或者修改测试\n\nbuild ：影响构建系统或外部依赖项的更改(maven,gradle,npm 等等)\n\nci ：对CI配置文件和脚本的更改\n\nchore ：对非 src 和 test 目录的修改（日常事务; 例行工作; 令人厌烦的任务; 乏味无聊的工作;）\n\nrevert ：Revert a commit\n\n\n","slug":"IDEA安装插件Git","date":"2022-12-02T08:33:27.000Z","categories_index":"程序猿🐒,工具,IDEA","tags_index":"IDEA","author_index":"慎独丶九思"},{"id":"b2fa8d65f49cd75139e7cbb96aa53d91","title":"Nexus在访问的时候报错","content":"Connect to sonatype-download.global.ssl.fastly.net:443nexus在访问的时候报错org.apache.http.conn.HttpHostConnectException: Connect to sonatype-download.global.ssl.fastly.net:443 [sonatype-download.global.ssl.fastly.net&#x2F;67.230.169.182] failed: Connection refused (Connection refused)\n\tat org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)\n\tat org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)\n\tat org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)\n\tat org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)\n\tat org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)\n\tat org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)\n\tat org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)\n\tat org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)\n\tat org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)\n\tat com.sonatype.nexus.plugins.outreach.internal.outreach.OutreachConnector.head(OutreachConnector.java:129)\n\tat com.sonatype.nexus.plugins.outreach.internal.outreach.SonatypeOutreach.remote(SonatypeOutreach.java:197)\n\tat com.sonatype.nexus.plugins.outreach.internal.outreach.SonatypeOutreach.getPageBundle(SonatypeOutreach.java:162)\n\tat com.sonatype.nexus.plugins.outreach.Outreach$getPageBundle$1.call(Unknown Source)\n\tat com.sonatype.nexus.plugins.outreach.internal.OutreachServlet.doGet(OutreachServlet.groovy:75)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:286)\n\tat com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:276)\n\tat com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:181)\n\tat com.google.inject.servlet.DynamicServletPipeline.service(DynamicServletPipeline.java:71)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)\n\tat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:112)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)\n\tat org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\n\tat org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\n\tat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n\tat org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\n\tat org.sonatype.nexus.security.SecurityFilter.executeChain(SecurityFilter.java:85)\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\n\tat org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\n\tat org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\n\tat org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)\n\tat org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\n\tat org.sonatype.nexus.security.SecurityFilter.doFilterInternal(SecurityFilter.java:101)\n\tat org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat com.sonatype.nexus.licensing.internal.LicensingRedirectFilter.doFilter(LicensingRedirectFilter.java:108)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat com.codahale.metrics.servlet.AbstractInstrumentedFilter.doFilter(AbstractInstrumentedFilter.java:97)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat org.sonatype.nexus.internal.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:68)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat org.sonatype.nexus.internal.web.EnvironmentFilter.doFilter(EnvironmentFilter.java:101)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat org.sonatype.nexus.internal.web.HeaderPatternFilter.doFilter(HeaderPatternFilter.java:98)\n\tat com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)\n\tat com.google.inject.servlet.DynamicFilterPipeline.dispatch(DynamicFilterPipeline.java:104)\n\tat com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:135)\n\tat org.sonatype.nexus.bootstrap.osgi.DelegatingFilter.doFilter(DelegatingFilter.java:73)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1317)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1219)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\n\tat com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:175)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:531)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:352)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:281)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:102)\n\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:762)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:680)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)\n\tat org.sonatype.nexus.internal.httpclient.NexusSSLConnectionSocketFactory.connectSocket(NexusSSLConnectionSocketFactory.java:89)\n\tat org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)\n\t... 84 common frames omitted\n\n解决方法：登录帐号\n","slug":"Nexus在访问的时候报错","date":"2022-12-02T08:22:25.000Z","categories_index":"程序猿🐒,Nexus","tags_index":"Nexus","author_index":"慎独丶九思"},{"id":"f07087a5b7608a7953d9daff2f1e86c6","title":"AppleScript","content":"一、字符串使用规则字符串需使用双引号，不能使用单引号字符串中有引号时，需使用转义字符””，如”\\他说:”你好！””\n字符串拼接set str to &quot;hello world&quot;\nset str2 to &quot;good morning &quot;\nset str3 to str2 &amp; str\n\n获取长度set num to the length of str3\n转类型set countStr to 100 as string\n切割set str4 to &quot;a-b-c-d-e&quot;\n方法1：获取由每一个字符组成的数组get every character of str4方法2：按照指定的分隔符分割字符串\nset oldDelimiters to AppleScript&#39;s text item delimiters --记录开始的去限器\nset AppleScript&#39;s text item delimiters to &quot;-&quot; --设置分隔符\nset str4Arr to every text item of str4 -- 分割\nset AppleScript&#39;s text item delimiters to oldDelimiters -- 恢复原来的去限器\nget str4Arr --获取数组\n\n比较begins with 或starts with ——以...开头\ndoes not start with ——不以。。。开头\nends with ——以。。。结束\nis equal to —— 相等\ncomes before —— 在。。。之前。比较两字符的ascii码\ncomes after ——在。。。之后。比较两字符的ascii码\nis in —— 在。。。之中\nis not in ——不在。。。中\ncontains ——包含\ndoes not contain ——不包含\n\n二、数组形式以大括号括起来，元素的类型无限制，如{“hello”,123,”world”}\n设置set arr1 to &#123;&quot;hello&quot;, 123, &quot;word&quot;, &quot;!&quot;&#125; --元素类型无限制\nset arr2 to &#123;&quot;good&quot;, &quot;morning&quot;, &quot;!&quot;&#125;\n\n合并set arr3 to arr1 &amp; arr2  -- 合并\n\n获取元素个数get the length of arr3\nget the count of arr3\n\n获取值&#x3D;&#x3D;注：list的序号从1开始&#x3D;&#x3D;\nget item 2 of arr3  -- 获取第二个元素，即123\nget 2nd item of arr3\nget the second item of arr3 --该种方式只能用到tenth \nget item -1 of arr3 -- -1表示最后一个，-2表示倒数第2个。。。\nget items 2 through 5 of arr3 -- 获取第2到第5个元素\n\n添加元素set the end of arr3 to &quot;new&quot;  --在最后添加一个元素“new”\n未解决: 在指定的位置插入值 ???\n更改值set arr to &#123;&quot;张三&quot;, &quot;李四&quot;, &quot;王五&quot;, &quot;谢六&quot;&#125;\n--set the item 2 of arr to &quot;胜七&quot;\n--set the 2nd item of arr to &quot;胜七&quot;\n--set the second item of arr to &quot;胜七&quot;\nget arr\n\n获取逆序后的数组get reverse of arr3\n\n随机获取数组的一个元素get some item of arr3\n\n类型转换get arr3 as string --将数组的元素凭借成一个字符串\n\n字符串切割成数组见-字符串\n按指定的符号将数组拼接成字符串set defaultDelimiters to AppleScript&#39;s text item delimiters\nset AppleScript&#39;s text item delimiters to &quot;-&quot;\nset arr3Str to arr3 as string\nset AppleScript&#39;s text item delimiters to defaultDelimiters\nget arr3Str","slug":"AppleScript","date":"2022-12-02T08:20:43.000Z","categories_index":"程序猿🐒,奇怪的Mac知识点💻,AppleScript,Script","tags_index":"MAC,Script","author_index":"慎独丶九思"},{"id":"59b9e410bb69677d20405f71f974caf1","title":"群晖第三方社群套件资源","content":"\n\n\n\n名称\n位置\n\n\n\nSynoCommunity\nhttp://packages.synocommunity.com\n\n\nSynoCommunity(Beta)\nhttp://packages.synocommunity.com/?beta=1\n\n\nACMENet\nhttp://synology.acmenet.ru\n\n\ncommunity package hub\nhttp://www.cphub.net\n\n\nGoSSPKS\nhttp://packages.jdel.org/\n\n\nJaspr\nhttp://jaspr.kastner.wtf/\n\n\nCambier\nhttps://synology.cambier.org/\n\n\nDiablos Netzwerk\nhttp://spk.diablos-netzwerk.de/\n\n\nDierkse\nhttp://syno.dierkse.nl/\n\n\nFileBot\nhttps://get.filebot.net/syno/\n\n\nHildinger\nhttp://www.hildinger.us/sspks/\n\n\nMarco Näf\nhttp://spk.naefmarco.ch/spkrepo/packages/\n\n\nNetzbär\nhttps://spk.netzbaer.de/\n\n\nNZB Usenet\nhttp://synology.nzbusenet.com/\n\n\nPage 81\nhttp://packages.page81.net/\n\n\nPC LOAD LETTER\nhttp://packages.pcloadletter.co.uk/\n\n\nPulseStation\nhttp://www.pulse-station.com/repo/\n\n\nSysCo.ch\nhttp://synology.sysco.ch\n\n\nspk.unzureichende.info\nhttp://spk.unzureichende.info/\n\n\n","slug":"群晖第三方社群套件资源","date":"2022-12-01T13:27:07.000Z","categories_index":"","tags_index":"群晖,NAS","author_index":"慎独丶九思"},{"id":"fd14a765516dcc449f419a4c47c22207","title":"Docker容器日志清理","content":"1.先查看磁盘空间\ndf -h\n\n2.找到容器的containerId-json.log文件,并清理(治标不治本，log迟早还会大的)\n查看各个容器的log文件大小\nfind &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F; -name *-json.log |xargs du -sh\n\n执行清理\n$ cat &#x2F;dev&#x2F;null &gt; &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;dfe25896671f0def031c5ffeb12dd335f7f54212c6ca5d3aca1c3f50b5e1eec4&#x2F;dfe25896671f0def031c5ffeb12dd335f7f54212c6ca5d3aca1c3f50b5e1eec4-json.log\n\n3.脚本化清理\n如果docker容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在Linux或者Unix系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat &#x2F;dev&#x2F;null &gt; *-json.log，当然你也可以通过rm -rf删除后重启docker。接下来，提供一个日志清理脚本clean_docker_log.sh，内容如下：\n#!&#x2F;bin&#x2F;sh\n\necho &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; start clean docker containers logs &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;\n\nlogs&#x3D;$(find &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F; -name *-json.log)\n\nfor log in $logs\n\tdo\n\t\techo &quot;clean logs : $log&quot;\n\t\tcat &#x2F;dev&#x2F;null &gt; $log\n\tdone\n\necho &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; end clean docker containers logs &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;\n\n# chmod +x clean_docker_log.sh\n# .&#x2F;clean_docker_log.sh\n\n但是，这样清理之后，随着时间的推移，容器日志会像杂草一样，卷土重来。\n4.设置Docker容器日志大小（治本）\n设置一个容器服务的日志大小上限\n上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器docker-compose的max-size选项来实现\nversion: &#39;3.3&#39;\nservices:\n  elasticsearch:\n    image: docker.elastic.co&#x2F;elasticsearch&#x2F;elasticsearch:7.5.0\n    container_name: elasticsearch\n    restart: always\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n    ports:\n      - 9200:9200\n    environment:\n      - discovery.type&#x3D;single-node\n      - bootstrap.memory_lock&#x3D;true\n      - &quot;ES_JAVA_OPTS&#x3D;-Xms512m -Xmx512m&quot;\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n  skywalking-oap:\n    image: apache&#x2F;skywalking-oap-server:6.6.0-es7\n    container_name: skywalking-oap\n    depends_on:\n      - elasticsearch\n    links:\n      - elasticsearch\n    restart: always\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n    ports:\n      - 11800:11800\n      - 12800:12800\n    environment:\n      - SW_STORAGE&#x3D;elasticsearch\n      - SW_STORAGE_ES_CLUSTER_NODES&#x3D;elasticsearch:9200\n  skywalking-ui:\n    image: apache&#x2F;skywalking-ui:6.6.0\n    container_name: skywalking-ui\n    depends_on:\n      - skywalking-oap\n    links:\n      - skywalking-oap\n    restart: always\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n    ports:\n      - 8480:8080\n    environment:\n      - SW_OAP_ADDRESS&#x3D;skywalking-oap:12800\n  nmg-monitor:\n    image: renren_io:2.0\n    container_name: nmg-monitor\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-monitor.jar:&#x2F;app&#x2F;app.jar\n  nmg-gateway:\n    image: renren_io:2.0\n    container_name: nmg-gateway\n    ports:\n      - &quot;8080:8080&quot;\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-gateway\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-gateway.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-auth:\n    image: renren_io:2.0\n    container_name: nmg-auth\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-auth\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-auth.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-admin:\n    image: renren_io:2.0\n    container_name: nmg-admin-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-admin\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-admin-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-oss:\n    image: renren_io:2.0\n    container_name: nmg-oss-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-oss-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-oss-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-job:\n    image: renren_io:2.0\n    container_name: nmg-job-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-job-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-job-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-message:\n    image: renren_io:2.0\n    container_name: nmg-message-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-message-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-message-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-flow:\n    image: renren_io:2.0\n    container_name: nmg-flow-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-flow-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-flow-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-api:\n    image: renren_io:2.0\n    container_name: nmg-api-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-api-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-api-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-cyyc:\n    image: renren_io:2.0\n    container_name: nmg-cyyc-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-cyyc-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-cyyc-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-metadata:\n    image: renren_io:2.0\n    container_name: nmg-metadata-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-metadata-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-metadata-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-qggb:\n    image: renren_io:2.0\n    container_name: nmg-qggb-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-qggb-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-qggb-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-qggwy:\n    image: renren_io:2.0\n    container_name: nmg-qggwy-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-qggwy-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-qggwy-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-dy:\n    image: renren_io:2.0\n    container_name: nmg-dy-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-dy-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-dy-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-cjgb:\n    image: renren_io:2.0\n    container_name: nmg-cjgb-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-cjgb-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-cjgb-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n  nmg-datav:\n    image: renren_io:2.0\n    container_name: nmg-datav-server\n    links:\n      - skywalking-oap\n    environment:\n      - SW_AGENT_NAME&#x3D;nmg-datav-server\n      - SW_AGENT_COLLECTOR_BACKEND_SERVICES&#x3D;skywalking-oap:11800\n    env_file:\n      - common.env\n    volumes:\n      - &#x2F;home&#x2F;xhzc&#x2F;nmg_gwy_cloud&#x2F;jar&#x2F;renren-datav-server.jar:&#x2F;app&#x2F;app.jar\n    logging:\n      driver: &quot;json-file&quot;\n      options:\n        max-size: &quot;5g&quot;\n\n重启nginx容器之后，其日志文件的大小就被限制在5GB，再也不用担心了。\n全局设置新建&#x2F;etc&#x2F;docker&#x2F;daemon.json，若有就不用新建了。添加log-dirver和log-opts参数，样例如下：\n\n\n\n\n\n\n\n\n\nvim &#x2F;etc&#x2F;docker&#x2F;daemon.json\n&#123;\n\t&quot;log-dirver&quot;: &quot;json-file&quot;,\n\t&quot;log-opts&quot;: &#123;\n\t\t&quot;max-size&quot;: &quot;5g&quot;,\n\t\t&quot;max-file&quot;: &quot;3&quot;\n\t&#125;\n&#125;\n\nmax-size&#x3D;5g，意味着一个容器日志大小上限是5G，max-file&#x3D;3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。\n&#x2F;&#x2F; 重启docker守护进程\nsystemctl daemon-reload\nsystemctl restart docker\n\n\n\n\n\n\n\n\n\n\n注意：设置的日志大小，只对新建的容器有效。\n参考：[https://blog.csdn.net/yjk13703623757/article/details/80283729](\n","slug":"测试","date":"2022-12-01T12:34:53.000Z","categories_index":"程序猿🐒,Docker","tags_index":"Docker","author_index":"慎独丶九思"},{"id":"cd21b4e6b83aafed33281c82b1994424","title":"设置MAC版Mysql的配置文件","content":"设置MAC版Mysql的配置文件1. 背景\n\n\n\n\n\n\n\n\nMac安装的Mysql8默认不会生成配置文件所以我需要创建个配置文件去让其加载。\n使用 Navicat 导入备份的时候，出现了 This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its 的错误，备份里面是包含了创建的函数的，在本地环境和服务器环境不一样就报错了。百度后发现是由于以下原因导致：\n\n\n\n\n\n\n\n\n\n创建函数时必须指定我们的函数是否是\n\nDETERMINISTIC 不确定的\nNO SQL 没有 SQL 语句，当然也不会修改数据\nREADS SQL DATA 只是读取数据，当然也不会修改数据\nMODIFIES SQL DATA 要修改数据\nCONTAINS SQL 包含了 SQL 语句\n\n解决方法：\n1、在 MySQL 数据库中执行以下语句，临时生效，重启后失效\nset global log_bin_trust_function_creators&#x3D;TRUE;\n\n2、在配置文件 my.ini 的 [mysqld] 配置，永久生效\nlog_bin_trust_function_creators&#x3D;1\n解决方法如下：\n1、在 MySQL 数据库中执行以下语句，临时生效，重启后失效\nset global log_bin_trust_function_creators&#x3D;TRUE;\n\n2、在配置文件 my.ini 的 [mysqld] 配置，永久生效\nlog_bin_trust_function_creators&#x3D;1\n\n2. 配置文件2.1 创建my.cnfMySQL默认安装在/usr/local/mysql-8.0.29-macos12-arm64\n\n在&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;support-files文件夹下创建my.cnf 内容如下：\n# Example MySQL config file for small systems.\n#\n# This is for a system with little memory (&lt;&#x3D; 64M) where MySQL is only used\n# from time to time and it&#39;s important that the mysqld daemon\n# doesn&#39;t use much resources.\n#\n# MySQL programs look for option files in a set of\n# locations which depend on the deployment platform.\n# You can copy this option file to one of those\n# locations. For information about these locations, see:\n# http:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;mysql&#x2F;en&#x2F;option-files.html\n#\n# In this file, you can use all long options that a program supports.\n# If you want to know which options a program supports, run the program\n# with the &quot;--help&quot; option.\n# The following options will be passed to all MySQL clients\n[client]\ndefault-character-set&#x3D;utf8\n#password &#x3D; your_password\nport        &#x3D; 3336\nsocket      &#x3D; &#x2F;tmp&#x2F;mysql.sock\n# Here follows entries for some specific programs\n# The MySQL server\n[mysqld]\nsql_mode&#x3D;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\ndefault-storage-engine&#x3D;INNODB\ncharacter-set-server&#x3D;utf8\ncollation-server&#x3D;utf8_general_ci\nsocket      &#x3D; &#x2F;tmp&#x2F;mysql.sock\nlog_bin_trust_function_creators&#x3D;1\n# lower_case_table_names &#x3D; 1    # 是否对sql语句大小写敏感，1表示不敏感，即不区分大小写\n# skip-external-locking\n# key_buffer_size &#x3D; 16K\n# max_allowed_packet &#x3D; 1M\n# table_open_cache &#x3D; 4\n# sort_buffer_size &#x3D; 64K\n# read_buffer_size &#x3D; 256K\n# read_rnd_buffer_size &#x3D; 256K\n# net_buffer_length &#x3D; 2K\n# thread_stack &#x3D; 256K   # 该字段根据需要修改，默认是128K，我的是因为启动报了这个字段的错导致启动失败，所以我改成256K了\n\n# Don&#39;t listen on a TCP&#x2F;IP port at all. This can be a security enhancement,\n# if all processes that need to connect to mysqld run on the same host.\n# All interaction with mysqld must be made via Unix sockets or named pipes.\n# Note that using this option without enabling named pipes on Windows\n# (using the &quot;enable-named-pipe&quot; option) will render mysqld useless!\n#\n#skip-networking\nserver-id   &#x3D; 1\n# Uncomment the following if you want to log updates\n#log-bin&#x3D;mysql-bin\n# binary logging format - mixed recommended\n#binlog_format&#x3D;mixed\n# Causes updates to non-transactional engines using statement format to be\n# written directly to binary log. Before using this option make sure that\n# there are no dependencies between transactional and non-transactional\n# tables such as in the statement INSERT INTO t_myisam SELECT * FROM\n# t_innodb; otherwise, slaves may diverge from the master.\n#binlog_direct_non_transactional_updates&#x3D;TRUE\n# Uncomment the following if you are using InnoDB tables\n#innodb_data_home_dir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data\n#innodb_data_file_path &#x3D; ibdata1:10M:autoextend\n#innodb_log_group_home_dir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data\n# You can set .._buffer_pool_size up to 50 - 80 %\n# of RAM but beware of setting memory usage too high\n#innodb_buffer_pool_size &#x3D; 16M\n#innodb_additional_mem_pool_size &#x3D; 2M\n# Set .._log_file_size to 25 % of buffer pool size\n#innodb_log_file_size &#x3D; 5M\n#innodb_log_buffer_size &#x3D; 8M\n#innodb_flush_log_at_trx_commit &#x3D; 1\n#innodb_lock_wait_timeout &#x3D; 50\n[mysqldump]\nquick\n# max_allowed_packet &#x3D; 16M\n[mysql]\nno-auto-rehash\n# Remove the next comment character if you are not familiar with SQL\n#safe-updates\n[myisamchk]\n# key_buffer_size &#x3D; 8M\n# sort_buffer_size &#x3D; 8M\n[mysqlhotcopy]\ninteractive-timeout\n\n2.2 配置my.cnf\n2.3 重启数据库\n","slug":"设置MAC版Mysql的配置文件","date":"2022-12-01T02:12:51.000Z","categories_index":"程序猿🐒,奇怪的Mac知识点💻,MySQL,数据库","tags_index":"MAC,MySQL","author_index":"慎独丶九思"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-11-30T02:00:19.576Z","categories_index":"","tags_index":"","author_index":"慎独丶九思"}]